{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto Crime Network Analysis: Tracking Illicit Activity on Blockchain Networks\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### Problem Statement\n",
    "Cryptocurrencies have become a significant medium for cyber-enabled financial crimes including ransomware attacks, darknet market transactions, and financial scams. While blockchain transactions are public, identifying illicit activity patterns within massive transaction graphs remains a critical challenge.\n",
    "\n",
    "### Research Questions\n",
    "- **RQ1**: Can graph-structural properties of Bitcoin transactions distinguish illicit from licit activity?\n",
    "- **RQ2**: Do illicit patterns generalize to other crypto crimes like scams?\n",
    "\n",
    "### Goal\n",
    "Achieve **>70% accuracy** on labeled validation data for classifying transactions as illicit or licit. Apply the trained model to unknown transactions to generate risk scores for prioritization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. About the Data\n",
    "\n",
    "### Elliptic Bitcoin Dataset\n",
    "- **Size**: ~200,000 Bitcoin transactions\n",
    "- **Labels**: '1' (illicit), '2' (licit), 'unknown' (predict these)\n",
    "- **Structure**: Graph-based with transaction edges\n",
    "- **Class Imbalance**: ~9:1 licit to illicit ratio\n",
    "\n",
    "### Mendeley Scam Dataset\n",
    "- **Size**: ~1,245 records\n",
    "- **Features**: Transaction value, wallet age, velocity, fees\n",
    "- **Target**: Is_Scam (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Elliptic data\n",
    "elliptic_classes = pd.read_csv('data/elliptic_hugging/elliptic_txs_classes.csv')\n",
    "elliptic_edges = pd.read_csv('data/elliptic_hugging/elliptic_txs_edgelist.csv')\n",
    "\n",
    "print(f'Classes shape: {elliptic_classes.shape}')\n",
    "print(f'Edges shape: {elliptic_edges.shape}')\n",
    "print(f'\\nClass distribution:\\n{elliptic_classes[\"class\"].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labeled and unknown\n",
    "labeled_classes = elliptic_classes[elliptic_classes['class'] != 'unknown'].copy()\n",
    "labeled_classes['label'] = (labeled_classes['class'] == '1').astype(int)\n",
    "unknown_classes = elliptic_classes[elliptic_classes['class'] == 'unknown'].copy()\n",
    "\n",
    "print(f'Labeled: {len(labeled_classes)} (Illicit: {labeled_classes[\"label\"].sum()})')\n",
    "print(f'Unknown: {len(unknown_classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods\n",
    "\n",
    "### Manual Feature Engineering\n",
    "\n",
    "**Experiment 1 - Elliptic (Graph-Based):**\n",
    "\n",
    "We compute comprehensive graph-structural features:\n",
    "- **Degree features**: in-degree, out-degree, total degree, degree ratios\n",
    "- **Centrality measures**: PageRank, Betweenness, Closeness\n",
    "- **Clustering**: Local clustering coefficient\n",
    "- **Neighborhood**: avg neighbor degree, unique neighbors\n",
    "- **Community structure**: Louvain community detection\n",
    "- **Hub/Authority indicators**\n",
    "\n",
    "**Three Feature Sets:**\n",
    "- **Set A**: Transaction-only (from Elliptic's 166 features)\n",
    "- **Set B**: Graph-only (computed features)\n",
    "- **Set C**: Combined (A + B)\n",
    "\n",
    "**Experiment 2 - Mendeley (Behavioral):**\n",
    "\n",
    "Focus on transaction and wallet behavior patterns:\n",
    "- Transaction value, fees, input/output counts\n",
    "- Wallet age, balance, velocity\n",
    "- **Engineered features**: value/fee ratios, velocity per day, activity intensity\n",
    "- **NO graph features** (not a graph dataset)\n",
    "\n",
    "### Model Training Strategy\n",
    "\n",
    "**Experiment 1 - Elliptic:**\n",
    "\n",
    "- **Feature Set Ablation**: We train models on three feature sets (A, B, C) to quantify the contribution of graph features (RQ1)\n",
    "- **5-Fold Stratified Cross-Validation** with:\n",
    "  1. **SMOTE oversampling** on training folds (9.8% → 33% illicit)\n",
    "  2. **Three base models**: Logistic Regression, Random Forest, XGBoost\n",
    "  3. **Hyperparameter tuning**: GridSearchCV on XGBoost (72 configurations)\n",
    "  4. **Class imbalance**: SMOTE handles imbalance; XGBoost uses `scale_pos_weight=1` since training data is balanced after SMOTE\n",
    "  5. **Ensemble stacking**: Meta-learner combines all predictions\n",
    "\n",
    "**Experiment 2 - Mendeley:**\n",
    "\n",
    "- **Behavioral features only** (no graph structure available)\n",
    "- **Train/test split** (80/20) due to smaller dataset size\n",
    "- **Two models**: Logistic Regression and Random Forest, both with `class_weight='balanced'`\n",
    "- **Feature importance analysis** to identify most predictive behavioral patterns\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "\n",
    "- Primary: F1-Score (balances precision/recall)\n",
    "- Secondary: ROC-AUC, Precision, Recall\n",
    "- Threshold optimization per fold (Elliptic only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "G = nx.from_pandas_edgelist(elliptic_edges, 'txId1', 'txId2', create_using=nx.DiGraph())\n",
    "print(f'Graph: {G.number_of_nodes():,} nodes, {G.number_of_edges():,} edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import manual feature engineering\n",
    "from manual_feature_engineering import EllipticFeatureEngineer\n",
    "import multiprocessing\n",
    "import importlib\n",
    "import manual_feature_engineering\n",
    "# Reload module to pick up latest changes\n",
    "importlib.reload(manual_feature_engineering)\n",
    "from manual_feature_engineering import EllipticFeatureEngineer\n",
    "\n",
    "# Initialize feature engineer with explicit worker count (use all available cores)\n",
    "n_workers = multiprocessing.cpu_count()\n",
    "print(f'Using {n_workers} parallel workers for feature engineering')\n",
    "engineer = EllipticFeatureEngineer(G, elliptic_features_df=None, n_jobs=n_workers)\n",
    "\n",
    "# Compute graph-structural features (Feature Set B)\n",
    "print('Computing comprehensive graph features...')\n",
    "print('(PageRank, Centrality measures, Clustering, Communities)')\n",
    "labeled_features = engineer.compute_graph_features(\n",
    "    nodes=labeled_classes['txId'].values,\n",
    "    use_sampling=False  # Use full graph (no sampling bias)\n",
    ")\n",
    "\n",
    "# Add behavioral features\n",
    "print('Computing behavioral features...')\n",
    "labeled_behavioral = engineer.compute_behavioral_features(\n",
    "    nodes=labeled_classes['txId'].values\n",
    ")\n",
    "\n",
    "# Merge behavioral features with graph features\n",
    "labeled_features = labeled_features.merge(labeled_behavioral, on='txId')\n",
    "print(f'Features after behavioral merge: {labeled_features.shape}')\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ELLIPTIC'S PRE-COMPUTED FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print('Loading Elliptic pre-computed features...')\n",
    "# Read CSV without header - first column is txId, second is step, rest are features\n",
    "elliptic_features = pd.read_csv('data/elliptic_hugging/elliptic_txs_features.csv', header=None)\n",
    "# Rename columns: first is txId, second is step, rest are feature_0, feature_1, etc.\n",
    "elliptic_features.columns = ['txId', 'step'] + [f'feature_{i}' for i in range(elliptic_features.shape[1] - 2)]\n",
    "\n",
    "print(f'Elliptic features shape: {elliptic_features.shape}')\n",
    "print(f'Column names: txId, step, feature_0, feature_1, ... (total {elliptic_features.shape[1]} columns)')\n",
    "\n",
    "# Select top 30 features (columns 2:32, skip txId and step)\n",
    "# These 30 likely capture most variance among the 166\n",
    "elliptic_cols = elliptic_features.columns[2:32].tolist()\n",
    "print(f'Selected {len(elliptic_cols)} Elliptic features for model')\n",
    "\n",
    "# Filter to only labeled transactions\n",
    "labeled_elliptic = elliptic_features[\n",
    "    elliptic_features['txId'].isin(labeled_classes['txId'])\n",
    "][['txId'] + elliptic_cols].copy()\n",
    "\n",
    "print(f'Labeled transactions with Elliptic features: {labeled_elliptic.shape}')\n",
    "\n",
    "# Merge with existing features\n",
    "labeled_features_old_count = len(labeled_features.columns) - 1  # Exclude txId\n",
    "labeled_features = labeled_features.merge(labeled_elliptic, on='txId', how='left')\n",
    "labeled_features_new_count = len(labeled_features.columns) - 1\n",
    "\n",
    "print(f'\\nFeature count: {labeled_features_old_count} → {labeled_features_new_count}')\n",
    "print(f'New features added: {labeled_features_new_count - labeled_features_old_count}')\n",
    "\n",
    "# Handle any NaN from merge (unlikely but safe)\n",
    "labeled_features = labeled_features.fillna(0)\n",
    "\n",
    "# Add temporal features\n",
    "print('Computing temporal features...')\n",
    "# Reuse the already loaded elliptic_features DataFrame\n",
    "labeled_temporal = engineer.compute_temporal_features(\n",
    "    nodes=labeled_classes['txId'].values,\n",
    "    elliptic_features_df=elliptic_features[['txId', 'step']]\n",
    ")\n",
    "\n",
    "# Merge temporal features\n",
    "labeled_features = labeled_features.merge(labeled_temporal, on='txId')\n",
    "print(f'Features after temporal merge: {labeled_features.shape}')\n",
    "\n",
    "# Update labeled_data with new merged features\n",
    "labeled_data = labeled_classes.merge(labeled_features, on='txId')\n",
    "print(f'\\\\nFeatures computed: {labeled_data.shape}')\n",
    "print(f'Total feature count: {len(labeled_features.columns) - 1}')  # Exclude txId\n",
    "print('\\\\nFeature list:', [col for col in labeled_features.columns if col != 'txId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE SET SEPARATION FOR ABLATION STUDY (RQ1)\n",
    "# ============================================================================\n",
    "\n",
    "# Define three feature sets for ablation study\n",
    "# Set A: Elliptic transaction-only features (30 features)\n",
    "elliptic_cols = [f'feature_{i}' for i in range(30)]\n",
    "X_A = labeled_data[elliptic_cols].fillna(0)\n",
    "print(f'Feature Set A (Elliptic-only): {X_A.shape[1]} features')\n",
    "\n",
    "# Set B: Graph + behavioral + temporal features (exclude all feature_* columns)\n",
    "graph_behavioral_cols = [c for c in labeled_features.columns \n",
    "                         if c != 'txId' and not c.startswith('feature_')]\n",
    "X_B = labeled_data[graph_behavioral_cols].fillna(0)\n",
    "print(f'Feature Set B (Graph + Behavioral + Temporal): {X_B.shape[1]} features')\n",
    "print(f'  Includes: graph metrics, behavioral features, temporal features (step, step_ratio, etc.)')\n",
    "\n",
    "# Set C: Combined (A + B)\n",
    "feature_cols = [c for c in labeled_features.columns if c != 'txId']\n",
    "X_C = labeled_data[feature_cols].fillna(0)\n",
    "print(f'Feature Set C (Combined): {X_C.shape[1]} features')\n",
    "\n",
    "y = labeled_data['label']\n",
    "print(f'\\nTarget variable: {len(y)} samples')\n",
    "print(f'Class distribution: Licit={sum(y==0)}, Illicit={sum(y==1)}')\n",
    "print(f'Imbalance ratio: {sum(y==0)/sum(y==1):.1f}:1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE EVALUATION WITH CROSS-VALIDATION - ABLATION STUDY\n",
    "# ============================================================================\n",
    "%pip install xgboost\n",
    "%pip install imbalanced-learn\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def train_and_evaluate_models(X, y, feature_set_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate models using 5-fold stratified cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target variable\n",
    "    feature_set_name : str\n",
    "        Name of feature set (e.g., 'A', 'B', 'C') for tracking results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Contains cv_results_df, all_folds, best_gb_fold, meta_learner_final\n",
    "    \"\"\"\n",
    "    print('='*70)\n",
    "    print(f'CROSS-VALIDATION FOR FEATURE SET {feature_set_name}')\n",
    "    print('='*70)\n",
    "    print(f'Total samples: {len(X)}')\n",
    "    print(f'Features: {X.shape[1]}')\n",
    "    print(f'Class distribution: Licit={sum(y==0)}, Illicit={sum(y==1)}')\n",
    "    print(f'Imbalance ratio: {sum(y==0)/sum(y==1):.1f}:1')\n",
    "    \n",
    "    # 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_results = {\n",
    "        'fold': [],\n",
    "        'model': [],\n",
    "        'feature_set': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'roc_auc': [],\n",
    "        'optimal_threshold': []\n",
    "    }\n",
    "    \n",
    "    all_folds = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f'\\\\n--- FOLD {fold}/5 ---')\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        print(f'Train: {len(X_train)} | Val: {len(X_val)}')\n",
    "        print(f'Train distribution: {sum(y_train==1)/len(y_train):.1%} illicit')\n",
    "        \n",
    "        # ---- Apply SMOTE to balance training data ----\n",
    "        smote = SMOTE(sampling_strategy=0.5, random_state=42, k_neighbors=5)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        print(f'After SMOTE: {len(X_train_balanced)} samples ({sum(y_train_balanced==1)} illicit)')\n",
    "        \n",
    "        # ---- Logistic Regression ----\n",
    "        lr = LogisticRegression(C=0.1, class_weight='balanced', solver='liblinear',\n",
    "                                penalty='l1', max_iter=1000, random_state=42)\n",
    "        scaler = RobustScaler()\n",
    "        X_train_balanced_scaled = scaler.fit_transform(X_train_balanced)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        lr.fit(X_train_balanced_scaled, y_train_balanced)\n",
    "        \n",
    "        lr_proba = lr.predict_proba(X_val_scaled)[:, 1]\n",
    "        lr_pred = (lr_proba > 0.5).astype(int)\n",
    "        \n",
    "        fold_results['fold'].append(fold)\n",
    "        fold_results['model'].append('Logistic Regression')\n",
    "        fold_results['feature_set'].append(feature_set_name)\n",
    "        fold_results['accuracy'].append(accuracy_score(y_val, lr_pred))\n",
    "        fold_results['precision'].append(precision_score(y_val, lr_pred, zero_division=0))\n",
    "        fold_results['recall'].append(recall_score(y_val, lr_pred, zero_division=0))\n",
    "        fold_results['f1'].append(f1_score(y_val, lr_pred, zero_division=0))\n",
    "        fold_results['roc_auc'].append(roc_auc_score(y_val, lr_proba))\n",
    "        fold_results['optimal_threshold'].append(0.5)\n",
    "        \n",
    "        # ---- Random Forest ----\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=10,\n",
    "                                    class_weight='balanced_subsample', random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train_balanced, y_train_balanced)\n",
    "        \n",
    "        rf_proba = rf.predict_proba(X_val)[:, 1]\n",
    "        rf_pred = (rf_proba > 0.5).astype(int)\n",
    "        \n",
    "        fold_results['fold'].append(fold)\n",
    "        fold_results['model'].append('Random Forest')\n",
    "        fold_results['feature_set'].append(feature_set_name)\n",
    "        fold_results['accuracy'].append(accuracy_score(y_val, rf_pred))\n",
    "        fold_results['precision'].append(precision_score(y_val, rf_pred, zero_division=0))\n",
    "        fold_results['recall'].append(recall_score(y_val, rf_pred, zero_division=0))\n",
    "        fold_results['f1'].append(f1_score(y_val, rf_pred, zero_division=0))\n",
    "        fold_results['roc_auc'].append(roc_auc_score(y_val, rf_proba))\n",
    "        fold_results['optimal_threshold'].append(0.5)\n",
    "        \n",
    "        # ---- XGBoost with Hyperparameter Tuning ----\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1, 0.15],\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'subsample': [0.7, 0.8],\n",
    "            'min_child_weight': [1, 3],\n",
    "        }\n",
    "        \n",
    "        # SMOTE handles class imbalance; scale_pos_weight=1 since training data is balanced after SMOTE\n",
    "        xgb_base = xgb.XGBClassifier(\n",
    "            scale_pos_weight=1,  # Changed from 9: SMOTE balances the data\n",
    "            random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_base, param_grid,\n",
    "            cv=3,  # Inner 3-fold CV\n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print('  Running hyperparameter grid search (this may take 5-10 min)...')\n",
    "        grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "        xgb_model = grid_search.best_estimator_\n",
    "        \n",
    "        print(f'  Best params: {grid_search.best_params_}')\n",
    "        print(f'  Best CV F1: {grid_search.best_score_:.3f}')\n",
    "        \n",
    "        gb = xgb_model\n",
    "        gb_proba = gb.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold on validation fold\n",
    "        thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "        f1_scores_list = []\n",
    "        for t in thresholds:\n",
    "            pred_t = (gb_proba > t).astype(int)\n",
    "            f1_scores_list.append(f1_score(y_val, pred_t, zero_division=0))\n",
    "        \n",
    "        optimal_t = thresholds[np.argmax(f1_scores_list)]\n",
    "        gb_pred = (gb_proba > optimal_t).astype(int)\n",
    "        \n",
    "        fold_results['fold'].append(fold)\n",
    "        fold_results['model'].append('XGBoost (Optimized)')\n",
    "        fold_results['feature_set'].append(feature_set_name)\n",
    "        fold_results['accuracy'].append(accuracy_score(y_val, gb_pred))\n",
    "        fold_results['precision'].append(precision_score(y_val, gb_pred, zero_division=0))\n",
    "        fold_results['recall'].append(recall_score(y_val, gb_pred, zero_division=0))\n",
    "        fold_results['f1'].append(f1_score(y_val, gb_pred, zero_division=0))\n",
    "        fold_results['roc_auc'].append(roc_auc_score(y_val, gb_proba))\n",
    "        fold_results['optimal_threshold'].append(optimal_t)\n",
    "        \n",
    "        print(f'  LR F1={f1_score(y_val, lr_pred, zero_division=0):.3f} | RF F1={f1_score(y_val, rf_pred, zero_division=0):.3f} | GB F1={f1_score(y_val, gb_pred, zero_division=0):.3f} (threshold={optimal_t:.2f})')\n",
    "        \n",
    "        all_folds.append({\n",
    "            'fold': fold,\n",
    "            'X_train': X_train,\n",
    "            'X_val': X_val,\n",
    "            'y_train': y_train,\n",
    "            'y_val': y_val,\n",
    "            'scaler': scaler,\n",
    "            'lr': lr,\n",
    "            'rf': rf,\n",
    "            'gb': gb,\n",
    "            'lr_proba': lr_proba,\n",
    "            'rf_proba': rf_proba,\n",
    "            'gb_proba': gb_proba,\n",
    "            'gb_optimal_threshold': optimal_t\n",
    "        })\n",
    "    \n",
    "    cv_results_df = pd.DataFrame(fold_results)\n",
    "    \n",
    "    print('\\\\n' + '='*70)\n",
    "    print(f'RESULTS SUMMARY FOR FEATURE SET {feature_set_name}')\n",
    "    print('='*70)\n",
    "    \n",
    "    for model_name in cv_results_df['model'].unique():\n",
    "        model_df = cv_results_df[cv_results_df['model'] == model_name]\n",
    "        print(f'\\\\n{model_name}:')\n",
    "        print(f'  F1-Score:  {model_df[\"f1\"].mean():.3f} ± {model_df[\"f1\"].std():.3f}')\n",
    "        print(f'  ROC-AUC:   {model_df[\"roc_auc\"].mean():.3f} ± {model_df[\"roc_auc\"].std():.3f}')\n",
    "        print(f'  Precision: {model_df[\"precision\"].mean():.3f} ± {model_df[\"precision\"].std():.3f}')\n",
    "        print(f'  Recall:    {model_df[\"recall\"].mean():.3f} ± {model_df[\"recall\"].std():.3f}')\n",
    "    \n",
    "    # Store best fold models\n",
    "    best_gb_fold = max(all_folds, key=lambda f: f1_score(f['y_val'], (f['gb_proba'] > f['gb_optimal_threshold']).astype(int), zero_division=0))\n",
    "    \n",
    "    # Ensemble stacking\n",
    "    from sklearn.linear_model import LogisticRegression as MetaModel\n",
    "    meta_X = []\n",
    "    meta_y = []\n",
    "    \n",
    "    for fold in all_folds:\n",
    "        lr_val = fold['lr_proba']\n",
    "        rf_val = fold['rf_proba']\n",
    "        gb_val = fold['gb_proba']\n",
    "        fold_meta_X = np.column_stack([lr_val, rf_val, gb_val])\n",
    "        meta_X.append(fold_meta_X)\n",
    "        meta_y.append(fold['y_val'].values)\n",
    "    \n",
    "    X_meta = np.vstack(meta_X)\n",
    "    y_meta = np.hstack(meta_y)\n",
    "    meta_learner = MetaModel(random_state=42)\n",
    "    meta_learner.fit(X_meta, y_meta)\n",
    "    \n",
    "    return {\n",
    "        'cv_results_df': cv_results_df,\n",
    "        'all_folds': all_folds,\n",
    "        'best_gb_fold': best_gb_fold,\n",
    "        'meta_learner_final': meta_learner\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# RUN ABLATION STUDY FOR ALL FEATURE SETS\n",
    "# ============================================================================\n",
    "\n",
    "# Store results for all feature sets\n",
    "ablation_results = {}\n",
    "\n",
    "# Feature Set A: Elliptic transaction-only\n",
    "print('\\\\n' + '='*70)\n",
    "print('FEATURE SET A: ELLIPTIC TRANSACTION-ONLY')\n",
    "print('='*70)\n",
    "results_A = train_and_evaluate_models(X_A, y, 'A')\n",
    "ablation_results['A'] = results_A\n",
    "\n",
    "# Feature Set B: Graph + behavioral + temporal\n",
    "print('\\\\n' + '='*70)\n",
    "print('FEATURE SET B: GRAPH + BEHAVIORAL + TEMPORAL')\n",
    "print('='*70)\n",
    "results_B = train_and_evaluate_models(X_B, y, 'B')\n",
    "ablation_results['B'] = results_B\n",
    "\n",
    "# Feature Set C: Combined\n",
    "print('\\\\n' + '='*70)\n",
    "print('FEATURE SET C: COMBINED (A + B)')\n",
    "print('='*70)\n",
    "results_C = train_and_evaluate_models(X_C, y, 'C')\n",
    "ablation_results['C'] = results_C\n",
    "\n",
    "# Store combined results for backward compatibility (use Set C)\n",
    "cv_results_df = results_C['cv_results_df']\n",
    "all_folds = results_C['all_folds']\n",
    "best_gb_fold = results_C['best_gb_fold']\n",
    "meta_learner_final = results_C['meta_learner_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ABLATION STUDY SUMMARY TABLE\n",
    "# ============================================================================\n",
    "\n",
    "print('='*70)\n",
    "print('FEATURE SET ABLATION STUDY RESULTS (RQ1)')\n",
    "print('='*70)\n",
    "\n",
    "# Combine all results\n",
    "all_ablation_results = pd.concat([\n",
    "    ablation_results['A']['cv_results_df'],\n",
    "    ablation_results['B']['cv_results_df'],\n",
    "    ablation_results['C']['cv_results_df']\n",
    "])\n",
    "\n",
    "# Create summary table for XGBoost (best model)\n",
    "xgb_ablation = all_ablation_results[all_ablation_results['model'] == 'XGBoost (Optimized)']\n",
    "ablation_summary = []\n",
    "\n",
    "for feature_set in ['A', 'B', 'C']:\n",
    "    fs_data = xgb_ablation[xgb_ablation['feature_set'] == feature_set]\n",
    "    ablation_summary.append({\n",
    "        'Feature Set': feature_set,\n",
    "        'Description': {\n",
    "            'A': 'Elliptic transaction-only (30 features)',\n",
    "            'B': 'Graph + Behavioral + Temporal',\n",
    "            'C': 'Combined (A + B)'\n",
    "        }[feature_set],\n",
    "        'F1-Score': f\"{fs_data['f1'].mean():.3f} ± {fs_data['f1'].std():.3f}\",\n",
    "        'ROC-AUC': f\"{fs_data['roc_auc'].mean():.3f} ± {fs_data['roc_auc'].std():.3f}\",\n",
    "        'Precision': f\"{fs_data['precision'].mean():.3f} ± {fs_data['precision'].std():.3f}\",\n",
    "        'Recall': f\"{fs_data['recall'].mean():.3f} ± {fs_data['recall'].std():.3f}\"\n",
    "    })\n",
    "\n",
    "ablation_df = pd.DataFrame(ablation_summary)\n",
    "print('\\n' + ablation_df.to_string(index=False))\n",
    "\n",
    "# Also create summary for all models\n",
    "print('\\n' + '='*70)\n",
    "print('ABLATION RESULTS BY MODEL')\n",
    "print('='*70)\n",
    "\n",
    "for model_name in ['Logistic Regression', 'Random Forest', 'XGBoost (Optimized)']:\n",
    "    model_ablation = all_ablation_results[all_ablation_results['model'] == model_name]\n",
    "    print(f'\\n{model_name}:')\n",
    "    for feature_set in ['A', 'B', 'C']:\n",
    "        fs_data = model_ablation[model_ablation['feature_set'] == feature_set]\n",
    "        print(f'  Set {feature_set}: F1={fs_data[\"f1\"].mean():.3f}, ROC-AUC={fs_data[\"roc_auc\"].mean():.3f}')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('KEY FINDING FOR RQ1:')\n",
    "print('='*70)\n",
    "f1_A = xgb_ablation[xgb_ablation['feature_set'] == 'A']['f1'].mean()\n",
    "f1_B = xgb_ablation[xgb_ablation['feature_set'] == 'B']['f1'].mean()\n",
    "f1_C = xgb_ablation[xgb_ablation['feature_set'] == 'C']['f1'].mean()\n",
    "print(f'Set A (Transaction-only): F1 = {f1_A:.3f}')\n",
    "print(f'Set B (Graph features):   F1 = {f1_B:.3f}')\n",
    "print(f'Set C (Combined):          F1 = {f1_C:.3f}')\n",
    "print(f'\\nGraph-only models (Set B) perform about {abs(f1_B - f1_A):.2f} F1 worse than transaction-only (Set A).')\n",
    "print(f'However, combining them (Set C) improves F1 slightly over transaction-only, achieving the best performance with F1 = {f1_C:.3f}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL PERFORMANCE SUMMARY TABLE\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('MODEL PERFORMANCE ON VALIDATION SET (5-FOLD CROSS-VALIDATION)')\n",
    "print('='*70)\n",
    "\n",
    "# Create clean summary table\n",
    "summary_data = []\n",
    "for model_name in cv_results_df['model'].unique():\n",
    "    model_df = cv_results_df[cv_results_df['model'] == model_name]\n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': f\"{model_df['accuracy'].mean():.3f}\",\n",
    "        'Precision': f\"{model_df['precision'].mean():.3f}\",\n",
    "        'Recall': f\"{model_df['recall'].mean():.3f}\",\n",
    "        'F1-Score': f\"{model_df['f1'].mean():.3f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print('\\n' + summary_df.to_string(index=False))\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('✓ Best Model: XGBoost (Optimized) with F1-Score ≈ 0.92')\n",
    "print('='*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training & Cross-Validation\n",
    "\n",
    "We train three complementary models with 5-fold stratified cross-validation:\n",
    "\n",
    "1. **Logistic Regression** - Linear baseline with L1 regularization\n",
    "\n",
    "2. **Random Forest** - Ensemble for non-linear patterns\n",
    "\n",
    "3. **XGBoost** - Optimized gradient boosting with hyperparameter tuning\n",
    "\n",
    "**Improvements Applied:**\n",
    "\n",
    "- **SMOTE**: Balanced training data (9.8% → 33% illicit representation)\n",
    "\n",
    "- **XGBoost**: Faster and more accurate than standard Gradient Boosting\n",
    "\n",
    "- **Hyperparameter Tuning**: GridSearchCV with 3-fold inner CV\n",
    "\n",
    "- **Ensemble Stacking**: Meta-learner combines all models optimally\n",
    "\n",
    "See Cell 8 below for implementation and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Analysis\n",
    "\n",
    "**Cross-validation results (Combined Feature Set C):**\n",
    "\n",
    "| Model                  | F1-Score      | Precision     | Recall        | ROC-AUC       |\n",
    "|------------------------|---------------|---------------|---------------|---------------|\n",
    "| Logistic Regression    | ~0.56         | ~0.43         | ~0.82         | ~0.93         |\n",
    "| Random Forest          | ~0.90         | ~0.92         | ~0.87         | ~0.99         |\n",
    "| **XGBoost (Optimized)**| **~0.92**     | **~0.94**     | **~0.90**     | **~0.99**     |\n",
    "\n",
    "**Key Achievements:**\n",
    "\n",
    "- **XGBoost F1-Score around 0.92** on combined features (Set C)\n",
    "\n",
    "- **Transaction-only features (Set A) achieve F1 around 0.90**, showing Elliptic's pre-computed features carry strong signal\n",
    "\n",
    "- **Graph+behavioral+temporal features (Set B) alone achieve F1 around 0.62**, performing moderately but worse than transaction-only\n",
    "\n",
    "- **Combined features (Set C) provide the best performance**, with a small but real improvement over transaction-only\n",
    "\n",
    "**Additional visualizations and error analysis follow below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ROC-AUC AND CALIBRATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ---- ROC Curves ----\n",
    "ax = axes[0, 0]\n",
    "for fold_idx, fold in enumerate(all_folds):\n",
    "    fpr, tpr, _ = roc_curve(fold['y_val'], fold['gb_proba'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, alpha=0.7, label=f'Fold {fold[\"fold\"]} (AUC={roc_auc:.3f})')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves (Gradient Boosting)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- Precision-Recall Curves ----\n",
    "ax = axes[0, 1]\n",
    "for fold in all_folds:\n",
    "    precision, recall, _ = precision_recall_curve(fold['y_val'], fold['gb_proba'])\n",
    "    ax.plot(recall, precision, alpha=0.7, label=f'Fold {fold[\"fold\"]}')\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curves (Gradient Boosting)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- Calibration Curves ----\n",
    "ax = axes[1, 0]\n",
    "for fold in all_folds:\n",
    "    prob_true, prob_pred = calibration_curve(fold['y_val'], fold['gb_proba'], n_bins=10)\n",
    "    ax.plot(prob_pred, prob_true, 's-', alpha=0.7, label=f'Fold {fold[\"fold\"]}')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n",
    "ax.set_xlabel('Predicted Probability')\n",
    "ax.set_ylabel('True Frequency')\n",
    "ax.set_title('Calibration Curves (Gradient Boosting)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- F1-Score vs Threshold ----\n",
    "ax = axes[1, 1]\n",
    "for fold in all_folds:\n",
    "    thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "    f1_scores_list = [f1_score(fold['y_val'], (fold['gb_proba'] > t).astype(int), zero_division=0)\n",
    "                       for t in thresholds]\n",
    "    ax.plot(thresholds, f1_scores_list, 'o-', alpha=0.7, label=f'Fold {fold[\"fold\"]}')\n",
    "\n",
    "ax.set_xlabel('Decision Threshold')\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_title('F1-Score vs Threshold (Gradient Boosting)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axvline(x=0.5, color='red', linestyle='--', label='Default (0.5)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('evaluation_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Evaluation curves saved to evaluation_curves.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE & ERROR ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "# Use best GB model from cross-validation\n",
    "best_gb = best_gb_fold['gb']\n",
    "X_val_best = best_gb_fold['X_val']\n",
    "y_val_best = best_gb_fold['y_val']\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': best_gb.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print('\\\\n' + '='*70)\n",
    "print('TOP 15 MOST IMPORTANT FEATURES')\n",
    "print('='*70)\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Plot top 15\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_15 = importance_df.head(15)\n",
    "ax.barh(top_15['Feature'], top_15['Importance'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Top 15 Most Important Features (GB)')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ---- Error Analysis ----\n",
    "gb_proba_val = best_gb_fold['gb_proba']\n",
    "gb_pred_val = (gb_proba_val > best_gb_fold['gb_optimal_threshold']).astype(int)\n",
    "\n",
    "false_positives = (y_val_best == 0) & (gb_pred_val == 1)\n",
    "false_negatives = (y_val_best == 1) & (gb_pred_val == 0)\n",
    "true_positives = (y_val_best == 1) & (gb_pred_val == 1)\n",
    "true_negatives = (y_val_best == 0) & (gb_pred_val == 0)\n",
    "\n",
    "print('\\\\n' + '='*70)\n",
    "print('ERROR ANALYSIS')\n",
    "print('='*70)\n",
    "print(f'True Positives (correctly flagged illicit):  {true_positives.sum():,}')\n",
    "print(f'True Negatives (correctly flagged licit):    {true_negatives.sum():,}')\n",
    "print(f'False Positives (licit flagged as illicit):  {false_positives.sum():,}')\n",
    "print(f'False Negatives (illicit flagged as licit):  {false_negatives.sum():,}')\n",
    "\n",
    "print('\\\\n--- False Positive Patterns (what licit txs look illicit?) ---')\n",
    "for feat in importance_df.head(5)['Feature'].values:\n",
    "    fp_mean = X_val_best[false_positives][feat].mean()\n",
    "    tn_mean = X_val_best[true_negatives][feat].mean()\n",
    "    tp_mean = X_val_best[true_positives][feat].mean()\n",
    "    print(f'{feat:30s}: FP={fp_mean:.3f}, TN={tn_mean:.3f}, TP={tp_mean:.3f}')\n",
    "\n",
    "print('\\\\n--- False Negative Patterns (what illicit txs look licit?) ---')\n",
    "for feat in importance_df.head(5)['Feature'].values:\n",
    "    fn_mean = X_val_best[false_negatives][feat].mean()\n",
    "    tp_mean = X_val_best[true_positives][feat].mean()\n",
    "    tn_mean = X_val_best[true_negatives][feat].mean()\n",
    "    print(f'{feat:30s}: FN={fn_mean:.3f}, TP={tp_mean:.3f}, TN={tn_mean:.3f}')\n",
    "\n",
    "print('\\\\n✓ Feature importance plot saved to feature_importance.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMMUNITY STRUCTURE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\\\n' + '='*70)\n",
    "print('COMMUNITY STRUCTURE ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "if 'community_id' in labeled_data.columns:\n",
    "    # Count total number of communities\n",
    "    n_communities = labeled_data['community_id'].nunique()\n",
    "    print(f'Total number of communities: {n_communities}')\n",
    "    \n",
    "    # Analyze largest communities\n",
    "    community_sizes = labeled_data.groupby('community_id').size().sort_values(ascending=False)\n",
    "    print(f'\\\\nTop 10 largest communities:')\n",
    "    print(community_sizes.head(10))\n",
    "    \n",
    "    # Compute illicit ratios for largest communities\n",
    "    print('\\\\n' + '-'*70)\n",
    "    print('ILLICIT RATIOS IN TOP 10 LARGEST COMMUNITIES')\n",
    "    print('-'*70)\n",
    "    \n",
    "    top_communities = community_sizes.head(10).index\n",
    "    community_analysis = []\n",
    "    \n",
    "    for comm_id in top_communities:\n",
    "        comm_data = labeled_data[labeled_data['community_id'] == comm_id]\n",
    "        n_illicit = comm_data['label'].sum()\n",
    "        n_licit = len(comm_data) - n_illicit\n",
    "        illicit_ratio = n_illicit / len(comm_data) if len(comm_data) > 0 else 0\n",
    "        \n",
    "        community_analysis.append({\n",
    "            'Community ID': comm_id,\n",
    "            'Size': len(comm_data),\n",
    "            'Illicit': n_illicit,\n",
    "            'Licit': n_licit,\n",
    "            'Illicit Ratio': f'{illicit_ratio:.3f}'\n",
    "        })\n",
    "    \n",
    "    comm_df = pd.DataFrame(community_analysis)\n",
    "    print(comm_df.to_string(index=False))\n",
    "    \n",
    "    # Overall community distribution\n",
    "    overall_illicit_ratio = labeled_data['label'].mean()\n",
    "    print(f'\\\\nOverall illicit ratio in dataset: {overall_illicit_ratio:.3f}')\n",
    "    \n",
    "    # Count communities with high illicit concentration\n",
    "    high_illicit_communities = []\n",
    "    for comm_id in labeled_data['community_id'].unique():\n",
    "        comm_data = labeled_data[labeled_data['community_id'] == comm_id]\n",
    "        if len(comm_data) >= 10:  # Only consider communities with at least 10 nodes\n",
    "            illicit_ratio = comm_data['label'].mean()\n",
    "            if illicit_ratio > overall_illicit_ratio * 2:  # 2x higher than average\n",
    "                high_illicit_communities.append({\n",
    "                    'community_id': comm_id,\n",
    "                    'size': len(comm_data),\n",
    "                    'illicit_ratio': illicit_ratio\n",
    "                })\n",
    "    \n",
    "    print(f'\\\\nCommunities with illicit ratio > 2x average ({overall_illicit_ratio*2:.3f}): {len(high_illicit_communities)}')\n",
    "    \n",
    "else:\n",
    "    print('Warning: community_id column not found in labeled_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Graph Feature Analysis\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "Based on the analysis above, illicit transactions exhibit distinct structural patterns compared to licit ones:\n",
    "\n",
    "1. **Lower Connectivity**: Illicit nodes have **lower degree** than licit nodes (ratio ~0.65x), indicating they appear in sparser graph regions. This suggests illicit actors may intentionally limit their connections to avoid detection.\n",
    "\n",
    "2. **Reduced Clustering**: Illicit nodes show **significantly lower clustering coefficients** (ratio ~0.04x), meaning they are less likely to be part of tightly-knit transaction groups. This aligns with money laundering patterns where transactions are spread across multiple intermediaries.\n",
    "\n",
    "3. **Centrality Measures**: PageRank and betweenness centrality are **near zero for both classes** and are **not strongly discriminative**. These centrality metrics do not help distinguish illicit from licit nodes in this dataset.\n",
    "\n",
    "4. **Flow Patterns**: The flow imbalance ratio (~0.80x) suggests illicit transactions have slightly different input/output patterns, though the difference is moderate.\n",
    "\n",
    "5. **Community Structure**: The community analysis reveals some concentration of illicit nodes in specific communities, though illicit activity is generally distributed across the network.\n",
    "\n",
    "**Important**: Contrary to initial hypotheses, **illicit nodes tend to have lower degree and lower clustering than licit nodes**, indicating they lie in sparser, less tightly connected regions of the transaction graph. Degree, clustering, community membership, and chain/flow-based behavioral features are the **more useful structural signals**, while centrality measures like PageRank and betweenness provide little discriminative value.\n",
    "\n",
    "This aligns with the ablation study: graph-only models (Set B, F1 ~0.62) are weaker than transaction-only models (Set A, F1 ~0.90), but the structural features still add marginal lift when combined with Elliptic's transaction features (Set C, F1 ~0.92).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploratory Analysis: Predicting Unknown Transactions\n",
    "\n",
    "**Important Note**: This section is exploratory and not part of the formal evaluation for RQ1 or RQ2.\n",
    "\n",
    "- **No Ground Truth**: There is no ground truth for the unknown transactions, so we cannot evaluate prediction accuracy.\n",
    "- **Risk Scores**: The outputs are risk scores and prioritization tools, not validated predictions.\n",
    "- **Use Case**: These predictions can be used to prioritize transactions for manual review or further investigation, but should not be treated as definitive classifications.\n",
    "\n",
    "This analysis belongs in the \"Exploratory / Future Work\" category and demonstrates how the trained models can be applied to new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 – Mendeley Scam Dataset (RQ2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 2: MENDELEY SCAM DATASET\n",
    "# ============================================================================\n",
    "\n",
    "from manual_feature_engineering import MendeleyFeatureEngineer, load_mendeley_data\n",
    "\n",
    "# Load Mendeley dataset\n",
    "print('='*70)\n",
    "print('LOADING MENDELEY CRYPTOCURRENCY SCAM DATASET')\n",
    "print('='*70)\n",
    "mendeley_df = load_mendeley_data(\n",
    "    'data/Cryptocurrency_Scam_Dataset_for_DQN_Models/Cryptocurrency_Scam_Dataset_for_DQN_Models.csv'\n",
    ")\n",
    "\n",
    "# Engineer features\n",
    "print('\\\\n' + '='*70)\n",
    "print('ENGINEERING BEHAVIORAL FEATURES')\n",
    "print('='*70)\n",
    "mendeley_engineer = MendeleyFeatureEngineer(mendeley_df)\n",
    "X_mend, y_mend, scaler_mend = mendeley_engineer.prepare_for_modeling(target_col='Is_Scam', scale=False)\n",
    "\n",
    "print(f'\\\\nFeature matrix shape: {X_mend.shape}')\n",
    "print(f'Target distribution:')\n",
    "print(y_mend.value_counts())\n",
    "print(f'Scam rate: {y_mend.mean():.2%}')\n",
    "\n",
    "# Train/test split (smaller dataset, so use split instead of full CV)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_mend, X_test_mend, y_train_mend, y_test_mend = train_test_split(\n",
    "    X_mend, y_mend, test_size=0.2, random_state=42, stratify=y_mend\n",
    ")\n",
    "\n",
    "print(f'\\\\nTrain: {len(X_train_mend)} samples ({y_train_mend.mean():.2%} scam)')\n",
    "print(f'Test:  {len(X_test_mend)} samples ({y_test_mend.mean():.2%} scam)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN MODELS ON MENDELEY DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print('='*70)\n",
    "print('TRAINING MODELS ON MENDELEY DATASET')\n",
    "print('='*70)\n",
    "\n",
    "# Scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_mend = StandardScaler()\n",
    "X_train_mend_scaled = scaler_mend.fit_transform(X_train_mend)\n",
    "X_test_mend_scaled = scaler_mend.transform(X_test_mend)\n",
    "\n",
    "# Logistic Regression with class_weight='balanced'\n",
    "print('\\\\n--- Logistic Regression ---')\n",
    "lr_mend = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "lr_mend.fit(X_train_mend_scaled, y_train_mend)\n",
    "\n",
    "lr_mend_proba = lr_mend.predict_proba(X_test_mend_scaled)[:, 1]\n",
    "lr_mend_pred = lr_mend.predict(X_test_mend_scaled)\n",
    "\n",
    "print(f'  F1-Score:  {f1_score(y_test_mend, lr_mend_pred, zero_division=0):.3f}')\n",
    "print(f'  Precision: {precision_score(y_test_mend, lr_mend_pred, zero_division=0):.3f}')\n",
    "print(f'  Recall:    {recall_score(y_test_mend, lr_mend_pred, zero_division=0):.3f}')\n",
    "print(f'  ROC-AUC:   {roc_auc_score(y_test_mend, lr_mend_proba):.3f}')\n",
    "\n",
    "# Random Forest with class_weight='balanced'\n",
    "print('\\\\n--- Random Forest ---')\n",
    "rf_mend = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=10, \n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_mend.fit(X_train_mend, y_train_mend)\n",
    "\n",
    "rf_mend_proba = rf_mend.predict_proba(X_test_mend)[:, 1]\n",
    "rf_mend_pred = rf_mend.predict(X_test_mend)\n",
    "\n",
    "print(f'  F1-Score:  {f1_score(y_test_mend, rf_mend_pred, zero_division=0):.3f}')\n",
    "print(f'  Precision: {precision_score(y_test_mend, rf_mend_pred, zero_division=0):.3f}')\n",
    "print(f'  Recall:    {recall_score(y_test_mend, rf_mend_pred, zero_division=0):.3f}')\n",
    "print(f'  ROC-AUC:   {roc_auc_score(y_test_mend, rf_mend_proba):.3f}')\n",
    "\n",
    "# Store results\n",
    "mendeley_results = {\n",
    "    'lr': {\n",
    "        'f1': f1_score(y_test_mend, lr_mend_pred, zero_division=0),\n",
    "        'precision': precision_score(y_test_mend, lr_mend_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test_mend, lr_mend_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_test_mend, lr_mend_proba)\n",
    "    },\n",
    "    'rf': {\n",
    "        'f1': f1_score(y_test_mend, rf_mend_pred, zero_division=0),\n",
    "        'precision': precision_score(y_test_mend, rf_mend_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test_mend, rf_mend_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_test_mend, rf_mend_proba)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS FOR MENDELEY\n",
    "# ============================================================================\n",
    "\n",
    "print('='*70)\n",
    "print('FEATURE IMPORTANCE ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "# Random Forest feature importance\n",
    "print('\\\\n--- Random Forest: Top 15 Most Important Features ---')\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_mend.columns,\n",
    "    'Importance': rf_mend.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(rf_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Logistic Regression coefficients\n",
    "print('\\\\n--- Logistic Regression: Top 15 Largest Coefficient Magnitudes ---')\n",
    "lr_coef = pd.DataFrame({\n",
    "    'Feature': X_mend.columns,\n",
    "    'Coefficient': lr_mend.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(lr_mend.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(lr_coef.head(15)[['Feature', 'Coefficient']].to_string(index=False))\n",
    "\n",
    "# Plot top features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# RF importance\n",
    "ax = axes[0]\n",
    "top_rf = rf_importance.head(10)\n",
    "ax.barh(top_rf['Feature'], top_rf['Importance'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Top 10 Features (Random Forest)')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# LR coefficients\n",
    "ax = axes[1]\n",
    "top_lr = lr_coef.head(10)\n",
    "colors = ['red' if c < 0 else 'blue' for c in top_lr['Coefficient']]\n",
    "ax.barh(top_lr['Feature'], top_lr['Coefficient'], color=colors)\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_title('Top 10 Features (Logistic Regression)')\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mendeley_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\\\n✓ Feature importance plots saved to mendeley_feature_importance.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendeley Experiment Results and Comparison to Elliptic\n",
    "\n",
    "**Model Performance on Mendeley:**\n",
    "\n",
    "Performance is **modest**, only slightly better than random:\n",
    "- **Logistic Regression**: F1 ≈ 0.47, ROC-AUC ≈ 0.48\n",
    "- **Random Forest**: F1 ≈ 0.50, ROC-AUC ≈ 0.53\n",
    "\n",
    "These results indicate that the behavioral features alone have **limited discriminatory power** for distinguishing scams in this dataset. The near-random ROC-AUC values suggest the models struggle to reliably separate the two classes.\n",
    "\n",
    "**Most Predictive Features:**\n",
    "\n",
    "The feature importance analysis reveals which behavioral patterns show some association with scams, though predictive power is weak:\n",
    "- Exchange rate and gas-adjusted values\n",
    "- Transaction velocity patterns\n",
    "- Wallet balance and value ratios\n",
    "- Fee-related metrics\n",
    "\n",
    "**Comparison to Elliptic Patterns:**\n",
    "\n",
    "**Partially Shared Risk Patterns:**\n",
    "- **High velocity**: Both datasets suggest abnormally high transaction velocity may indicate risk\n",
    "- **Abnormal value/fee ratios**: Transactions with unusual efficiency metrics appear in both contexts\n",
    "- **Activity intensity**: Sudden spikes in activity correlate with illicit behavior in both contexts\n",
    "\n",
    "**Key Differences:**\n",
    "- **Graph structure**: Elliptic benefits from graph features (though Set B alone underperforms Set A), while Mendeley has no graph structure\n",
    "- **Feature types**: Elliptic uses transaction-level graph metrics, while Mendeley focuses on wallet-level behavioral patterns\n",
    "- **Dataset size**: Mendeley is much smaller (~1,245 vs ~46,564 labeled), limiting model complexity\n",
    "- **Performance gap**: Elliptic achieves F1 ~0.92, while Mendeley achieves F1 ~0.47–0.50\n",
    "\n",
    "**RQ2 Answer**: Some behavioral anomalies—such as high transaction velocity, abnormal value/fee ratios, and young high-activity wallets—appear as risk indicators in both datasets, suggesting **weak, partial generalization**. However, overall generalization is limited and predictive performance on scams remains poor. The Mendeley models have **limited discriminatory power**, with performance only marginally above random chance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Analysis: What distinguishes illicit vs licit?\n",
    "print('\\\\n### GRAPH FEATURE ANALYSIS ###')\n",
    "print('Comparing illicit vs licit transactions:\\\\n')\n",
    "\n",
    "key_features = ['total_degree', 'pagerank', 'betweenness_centrality', \n",
    "                'clustering_coefficient', 'avg_neighbor_degree', 'flow_imbalance']\n",
    "\n",
    "for feat in key_features:\n",
    "    if feat in labeled_data.columns:\n",
    "        illicit_mean = labeled_data[labeled_data['label']==1][feat].mean()\n",
    "        licit_mean = labeled_data[labeled_data['label']==0][feat].mean()\n",
    "        ratio = illicit_mean / (licit_mean + 1e-6)\n",
    "        print(f'{feat:25s}: Illicit={illicit_mean:.4f}, Licit={licit_mean:.4f}, Ratio={ratio:.2f}x')\n",
    "\n",
    "print('\\\\n**Key Insight**: Graph features reveal structural differences between illicit and licit activity.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Model to Unknown Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREDICT UNKNOWN TRANSACTIONS WITH CONFIDENCE\n",
    "# ============================================================================\n",
    "\n",
    "print('Computing features for unknown transactions...')\n",
    "unknown_sample = unknown_classes['txId'].values[:10000]\n",
    "\n",
    "# Compute graph features\n",
    "unknown_features = engineer.compute_graph_features(unknown_sample, use_sampling=False)\n",
    "\n",
    "# Add behavioral features for unknown transactions\n",
    "print('Computing behavioral features for unknown transactions...')\n",
    "unknown_behavioral = engineer.compute_behavioral_features(unknown_sample)\n",
    "unknown_features = unknown_features.merge(unknown_behavioral, on='txId')\n",
    "\n",
    "# Add Elliptic pre-computed features for unknown transactions\n",
    "print('Loading Elliptic features for unknown transactions...')\n",
    "elliptic_features_raw = pd.read_csv('data/elliptic_hugging/elliptic_txs_features.csv', header=None)\n",
    "elliptic_features_raw.columns = ['txId', 'step'] + [f'feature_{i}' for i in range(elliptic_features_raw.shape[1] - 2)]\n",
    "\n",
    "# Select the same 30 Elliptic features used for labeled data\n",
    "elliptic_cols = elliptic_features_raw.columns[2:32].tolist()  # Same as in Cell 7\n",
    "\n",
    "# Filter to only unknown transactions\n",
    "unknown_elliptic = elliptic_features_raw[\n",
    "    elliptic_features_raw['txId'].isin(unknown_sample)\n",
    "][['txId'] + elliptic_cols].copy()\n",
    "\n",
    "print(f'Unknown transactions with Elliptic features: {unknown_elliptic.shape}')\n",
    "\n",
    "# Merge Elliptic features\n",
    "unknown_features = unknown_features.merge(unknown_elliptic, on='txId', how='left')\n",
    "unknown_features = unknown_features.fillna(0)  # Handle any missing values\n",
    "\n",
    "# Add temporal features for unknown\n",
    "unknown_temporal = engineer.compute_temporal_features(\n",
    "    nodes=unknown_sample,\n",
    "    elliptic_features_df=elliptic_features_raw[['txId', 'step']]\n",
    ")\n",
    "unknown_features = unknown_features.merge(unknown_temporal, on='txId')\n",
    "\n",
    "X_unknown = unknown_features[feature_cols].fillna(0)\n",
    "\n",
    "# Use best models from cross-validation\n",
    "best_gb_model = best_gb_fold['gb']\n",
    "best_lr_model = best_gb_fold['lr']\n",
    "best_rf_model = best_gb_fold['rf']\n",
    "best_scaler = best_gb_fold['scaler']\n",
    "best_threshold = best_gb_fold['gb_optimal_threshold']\n",
    "\n",
    "# Scale features using the scaler from best fold\n",
    "X_unknown_scaled = best_scaler.transform(X_unknown)\n",
    "\n",
    "# Predictions with confidence scores\n",
    "print('\\nGenerating predictions for unknown transactions...')\n",
    "lr_proba_unknown = best_lr_model.predict_proba(X_unknown_scaled)[:, 1]\n",
    "rf_proba_unknown = best_rf_model.predict_proba(X_unknown)[:, 1]\n",
    "gb_proba_unknown = best_gb_model.predict_proba(X_unknown)[:, 1]\n",
    "\n",
    "# Use meta-learner to combine predictions\n",
    "base_predictions = np.column_stack([\n",
    "    lr_proba_unknown,\n",
    "    rf_proba_unknown,\n",
    "    gb_proba_unknown\n",
    "])\n",
    "ensemble_proba = meta_learner_final.predict_proba(base_predictions)[:, 1]\n",
    "\n",
    "# ============================================================================\n",
    "# ANOMALY DETECTION LAYER\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print('Training anomaly detector...')\n",
    "\n",
    "# Train Isolation Forest on unknown transactions\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.1,  # Expect ~10% anomalies\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "iso_forest.fit(X_unknown)\n",
    "\n",
    "# Get anomaly scores for unknown transactions\n",
    "anomaly_scores = iso_forest.score_samples(X_unknown)  # Lower = more anomalous\n",
    "is_anomaly = iso_forest.predict(X_unknown) == -1  # -1 = anomaly, 1 = normal\n",
    "\n",
    "print(f'Detected {is_anomaly.sum()} anomalies ({is_anomaly.mean():.1%})')\n",
    "\n",
    "# Boost ensemble predictions for anomalies\n",
    "ensemble_proba_original = ensemble_proba.copy()\n",
    "\n",
    "# Increase probability for anomalous transactions\n",
    "# If anomalous AND high prob of illicit -> boost it\n",
    "ensemble_proba = np.where(\n",
    "    is_anomaly,\n",
    "    np.minimum(ensemble_proba * 1.3, 1.0),  # Boost by 30%, cap at 1.0\n",
    "    ensemble_proba\n",
    ")\n",
    "\n",
    "print(f'Probability range before anomaly boost: [{ensemble_proba_original.min():.3f}, {ensemble_proba_original.max():.3f}]')\n",
    "print(f'Probability range after anomaly boost:  [{ensemble_proba.min():.3f}, {ensemble_proba.max():.3f}]')\n",
    "\n",
    "gb_pred_unknown = (ensemble_proba > best_threshold).astype(int)\n",
    "\n",
    "# Create output dataframe with confidence\n",
    "predictions_df = pd.DataFrame({\n",
    "    'txId': unknown_sample,\n",
    "    'predicted_label': gb_pred_unknown,\n",
    "    'illicit_probability': ensemble_proba,  # Uses meta-learner ensemble (boosted by anomalies)\n",
    "    'confidence': np.abs(ensemble_proba - 0.5) * 2,  # Distance from decision boundary\n",
    "    'is_anomaly': is_anomaly,  # NEW: Anomaly flag\n",
    "    'anomaly_score': anomaly_scores,  # NEW: Anomaly score (lower = more anomalous)\n",
    "    'category': pd.cut(ensemble_proba, bins=[0, 0.25, 0.4, 0.6, 0.75, 1.0],\n",
    "                       labels=['Likely Licit', 'Uncertain (Licit)', 'Uncertain (Illicit)', 'Likely Illicit', 'Highly Illicit'])\n",
    "})\n",
    "\n",
    "# Sort by confidence\n",
    "predictions_df = predictions_df.sort_values('confidence', ascending=False)\n",
    "\n",
    "print(f'\\nPredicted {len(predictions_df)} unknown transactions')\n",
    "print(f'  Predicted illicit: {gb_pred_unknown.sum():,} ({gb_pred_unknown.mean():.1%})')\n",
    "print(f'  High confidence (>70%): {(predictions_df[\"confidence\"] > 0.7).sum():,}')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('PREDICTION CONFIDENCE DISTRIBUTION')\n",
    "print('='*70)\n",
    "print(predictions_df['category'].value_counts())\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('TOP 20 HIGHEST CONFIDENCE ILLICIT PREDICTIONS')\n",
    "print('='*70)\n",
    "top_illicit = predictions_df[predictions_df['predicted_label'] == 1].head(20)\n",
    "print(top_illicit[['txId', 'illicit_probability', 'confidence']].to_string(index=False))\n",
    "\n",
    "# Save predictions\n",
    "predictions_df.to_csv('unknown_predictions.csv', index=False)\n",
    "print('\\n✓ Predictions saved to unknown_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Storytelling and Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**RQ1 Answer**: Graph-structural, behavioral, and temporal features provide **modest but complementary** information that improves performance when combined with transaction features, even though transaction features are the dominant signal (F1 rising from ~0.90 to ~0.92).\n",
    "\n",
    "- **Transaction-only (Set A)**: F1 ~0.90 — the strongest single feature block\n",
    "- **Graph+behavioral+temporal (Set B)**: F1 ~0.62 — performs moderately but clearly weaker than Set A (≈0.28 lower F1)\n",
    "- **Combined (Set C)**: F1 ~0.92 — achieves the **best performance** with a small (~0.02) absolute improvement over Set A\n",
    "- **Illicit nodes have lower degree and lower clustering** than licit nodes, indicating they lie in sparser, less tightly connected regions of the transaction graph\n",
    "- PageRank and betweenness centrality are near zero for both classes and not strongly discriminative\n",
    "\n",
    "**RQ2 Answer**: Patterns show **weak behavioral overlap rather than strong predictive generalization** across crime types.\n",
    "\n",
    "- Some behavioral anomalies (high velocity, abnormal value/fee ratios, young high-activity wallets) appear as risk indicators in both Elliptic and Mendeley datasets\n",
    "- However, Mendeley models have **limited discriminatory power** (F1 ~0.47–0.50, ROC-AUC ~0.48–0.53), with performance only marginally above random chance\n",
    "- The absence of graph structure and smaller dataset size limit Mendeley's predictive capability\n",
    "\n",
    "**Unknown Transaction Predictions**: The predictions on unknown Elliptic transactions are **risk scores for prioritization**, not validated accuracy measurements. There is no ground truth for unknown nodes, so these outputs should be used to flag high-risk transactions for manual review rather than as definitive classifications. Performance metrics (e.g., meeting the 70% accuracy target) refer only to labeled validation data.\n",
    "\n",
    "### What We Learned\n",
    "1. Elliptic's pre-computed transaction features carry the strongest signal for illicit detection\n",
    "2. Graph-structural features provide marginal improvement when combined with transaction features\n",
    "3. Ensemble methods (XGBoost with SMOTE) improve reliability on imbalanced data\n",
    "4. Illicit nodes tend to be in sparser graph regions with lower connectivity and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Impact\n",
    "\n",
    "### Social Impact\n",
    "- Assists law enforcement in tracking cryptocurrency crimes\n",
    "- Protects users from scams and fraud\n",
    "- Increases trust in cryptocurrency ecosystems\n",
    "\n",
    "### Ethical Considerations\n",
    "- **Privacy concerns**: Transaction monitoring could affect legitimate users\n",
    "- **False positives**: Risk of flagging innocent transactions\n",
    "- **Transparency needed**: Classification decisions should be explainable\n",
    "- **Bias potential**: Training data may not represent all crime types\n",
    "\n",
    "### Future Work\n",
    "- Extend to other cryptocurrencies (Ethereum, etc.)\n",
    "- Real-time monitoring system\n",
    "- Deep learning approaches (GNNs)\n",
    "- Multi-chain analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Poster-Ready Visualizations\n",
    "\n",
    "The following visualizations are designed for presentation and poster use. Each figure is saved as a high-resolution PNG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 1: Illicit vs Licit Degree Distribution (Elliptic)\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Separate illicit and licit data\n",
    "illicit_degrees = labeled_data[labeled_data['label'] == 1]['total_degree']\n",
    "licit_degrees = labeled_data[labeled_data['label'] == 0]['total_degree']\n",
    "\n",
    "# Create overlapping KDE plot\n",
    "sns.kdeplot(licit_degrees, ax=ax, fill=True, alpha=0.5, label='Licit', color='steelblue')\n",
    "sns.kdeplot(illicit_degrees, ax=ax, fill=True, alpha=0.5, label='Illicit', color='crimson')\n",
    "\n",
    "ax.set_xlabel('Total Degree', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Degree Distribution: Illicit vs Licit Transactions (Elliptic)', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xlim(0, 20)  # Focus on the main distribution range\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add mean annotations\n",
    "ax.axvline(illicit_degrees.mean(), color='crimson', linestyle='--', alpha=0.8, label=f'Illicit mean: {illicit_degrees.mean():.2f}')\n",
    "ax.axvline(licit_degrees.mean(), color='steelblue', linestyle='--', alpha=0.8, label=f'Licit mean: {licit_degrees.mean():.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_degree_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: elliptic_degree_distribution.png')\n",
    "print(f'  Illicit mean degree: {illicit_degrees.mean():.2f}')\n",
    "print(f'  Licit mean degree: {licit_degrees.mean():.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Distribution Analysis\n",
    "\n",
    "This KDE plot compares the total degree (number of connections) for illicit vs licit transactions. **Illicit nodes have significantly lower average degree (~2.0) compared to licit nodes (~3.1)**, indicating that illicit transactions tend to occur in sparser regions of the transaction graph. This suggests illicit actors may intentionally limit their connections to avoid detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 2: Illicit vs Licit Clustering Coefficient Distribution (Elliptic)\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Separate illicit and licit data\n",
    "illicit_clustering = labeled_data[labeled_data['label'] == 1]['clustering_coefficient']\n",
    "licit_clustering = labeled_data[labeled_data['label'] == 0]['clustering_coefficient']\n",
    "\n",
    "# Create overlapping histogram (KDE doesn't work well for sparse data with many zeros)\n",
    "ax.hist(licit_clustering, bins=50, alpha=0.5, label='Licit', color='steelblue', density=True)\n",
    "ax.hist(illicit_clustering, bins=50, alpha=0.5, label='Illicit', color='crimson', density=True)\n",
    "\n",
    "ax.set_xlabel('Clustering Coefficient', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Clustering Coefficient Distribution: Illicit vs Licit (Elliptic)', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics\n",
    "ax.text(0.95, 0.95, f'Illicit mean: {illicit_clustering.mean():.4f}\\nLicit mean: {licit_clustering.mean():.4f}',\n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_clustering_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: elliptic_clustering_distribution.png')\n",
    "print(f'  Illicit mean clustering: {illicit_clustering.mean():.4f}')\n",
    "print(f'  Licit mean clustering: {licit_clustering.mean():.4f}')\n",
    "print(f'  Ratio (illicit/licit): {illicit_clustering.mean() / (licit_clustering.mean() + 1e-9):.2f}x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Coefficient Analysis\n",
    "\n",
    "This histogram compares the local clustering coefficient for illicit vs licit nodes. **Illicit nodes have dramatically lower clustering (~0.0004) compared to licit nodes (~0.008)—a ratio of about 0.04x.** This means illicit transactions are far less likely to be part of tightly-knit transaction groups. The pattern aligns with money laundering behavior where transactions are deliberately spread across multiple intermediaries to obscure the flow of funds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 3: Community-Level Illicit Percentages (Elliptic)\n",
    "# ============================================================================\n",
    "\n",
    "# Compute illicit percentage per community (minimum 50 nodes)\n",
    "community_stats = labeled_data.groupby('community_id').agg(\n",
    "    size=('label', 'count'),\n",
    "    illicit_count=('label', 'sum')\n",
    ").reset_index()\n",
    "community_stats['illicit_pct'] = (community_stats['illicit_count'] / community_stats['size']) * 100\n",
    "\n",
    "# Filter to communities with at least 50 nodes\n",
    "community_stats_filtered = community_stats[community_stats['size'] >= 50].copy()\n",
    "community_stats_filtered = community_stats_filtered.sort_values('illicit_pct', ascending=False)\n",
    "\n",
    "# Take top 15 communities by illicit percentage\n",
    "top_15_communities = community_stats_filtered.head(15)\n",
    "\n",
    "# Overall baseline\n",
    "overall_illicit_pct = labeled_data['label'].mean() * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars = ax.bar(range(len(top_15_communities)), top_15_communities['illicit_pct'], color='crimson', alpha=0.7)\n",
    "ax.axhline(y=overall_illicit_pct, color='black', linestyle='--', linewidth=2, label=f'Overall baseline: {overall_illicit_pct:.1f}%')\n",
    "\n",
    "ax.set_xlabel('Community ID', fontsize=12)\n",
    "ax.set_ylabel('Illicit Percentage (%)', fontsize=12)\n",
    "ax.set_title('Top 15 Communities by Illicit Concentration (Elliptic)', fontsize=14)\n",
    "ax.set_xticks(range(len(top_15_communities)))\n",
    "ax.set_xticklabels(top_15_communities['community_id'].astype(int), rotation=45, ha='right')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (idx, row) in enumerate(top_15_communities.iterrows()):\n",
    "    ax.text(i, row['illicit_pct'] + 0.5, f'{row[\"illicit_pct\"]:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_community_illicit_percent.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: elliptic_community_illicit_percent.png')\n",
    "print(f'  Overall illicit rate: {overall_illicit_pct:.1f}%')\n",
    "print(f'  Highest community illicit rate: {top_15_communities[\"illicit_pct\"].max():.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community-Level Illicit Concentration\n",
    "\n",
    "This bar chart shows the top 15 communities ranked by their percentage of illicit transactions (among communities with at least 50 nodes). The dashed line indicates the overall dataset baseline (~9.8%). **Some communities have illicit concentrations 2-3x higher than the baseline**, suggesting that certain network neighborhoods are more associated with illicit activity. This community structure information can help prioritize investigation efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 4: Feature Set A/B/C Performance Bar Chart (Elliptic)\n",
    "# ============================================================================\n",
    "\n",
    "# Extract F1 scores from ablation results (XGBoost - best model)\n",
    "f1_A = xgb_ablation[xgb_ablation['feature_set'] == 'A']['f1'].mean()\n",
    "f1_B = xgb_ablation[xgb_ablation['feature_set'] == 'B']['f1'].mean()\n",
    "f1_C = xgb_ablation[xgb_ablation['feature_set'] == 'C']['f1'].mean()\n",
    "\n",
    "feature_sets = ['Set A\\n(Transaction)', 'Set B\\n(Graph/Behavior)', 'Set C\\n(Combined)']\n",
    "f1_scores = [f1_A, f1_B, f1_C]\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bars = ax.bar(feature_sets, f1_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('F1-Score', fontsize=12)\n",
    "ax.set_title('Ablation Study: Feature Set Performance (XGBoost)', fontsize=14)\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, f1_scores):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "            f'{score:.3f}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_feature_set_f1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: elliptic_feature_set_f1.png')\n",
    "print(f'  Set A (Transaction-only): F1 = {f1_A:.3f}')\n",
    "print(f'  Set B (Graph/Behavior):   F1 = {f1_B:.3f}')\n",
    "print(f'  Set C (Combined):         F1 = {f1_C:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set Ablation Results\n",
    "\n",
    "This bar chart summarizes the ablation study comparing three feature sets. **Transaction-only features (Set A) dominate with F1 ~0.90**, showing that Elliptic's pre-computed transaction features carry strong predictive signal. **Graph/behavioral features alone (Set B) perform much weaker at F1 ~0.60.** However, **combining all features (Set C) yields the best performance at F1 ~0.92**, demonstrating that graph-structural features provide a small but real complementary lift when added to transaction features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 5: Confusion Matrix for Best Elliptic Model\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Get predictions from best fold\n",
    "y_val = best_gb_fold['y_val']\n",
    "gb_proba = best_gb_fold['gb_proba']\n",
    "optimal_threshold = best_gb_fold['gb_optimal_threshold']\n",
    "y_pred = (gb_proba > optimal_threshold).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Licit', 'Illicit'])\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "\n",
    "ax.set_title('Confusion Matrix: XGBoost on Combined Features (Set C)', fontsize=14)\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'✓ Saved: elliptic_confusion_matrix.png')\n",
    "print(f'  True Negatives (Licit correctly classified):  {tn:,}')\n",
    "print(f'  True Positives (Illicit correctly classified): {tp:,}')\n",
    "print(f'  False Positives (Licit misclassified as Illicit): {fp:,}')\n",
    "print(f'  False Negatives (Illicit misclassified as Licit): {fn:,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Analysis\n",
    "\n",
    "This confusion matrix shows the performance of the best XGBoost model on validation data. The model achieves **high true positive and true negative rates** with relatively few errors. Most illicit transactions (~820) are correctly identified, while only ~50 licit transactions are falsely flagged and ~90 illicit transactions are missed. This demonstrates strong discriminative ability with acceptable false positive/negative trade-offs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 6: Elliptic Feature Importance (High-Resolution Export)\n",
    "# ============================================================================\n",
    "\n",
    "# Use the already-computed importance_df from Cell 15\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_15 = importance_df.head(15)\n",
    "colors = ['#2ecc71' if 'feature_' in f else '#e74c3c' for f in top_15['Feature']]\n",
    "\n",
    "bars = ax.barh(top_15['Feature'], top_15['Importance'], color=colors, alpha=0.8)\n",
    "ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax.set_title('Top 15 Most Important Features (XGBoost - Combined Set C)', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add legend for feature types\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#2ecc71', alpha=0.8, label='Elliptic Transaction Features'),\n",
    "                   Patch(facecolor='#e74c3c', alpha=0.8, label='Graph/Behavioral Features')]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: elliptic_feature_importance.png (high-resolution)')\n",
    "print(f'  Most important feature: {top_15.iloc[0][\"Feature\"]} ({top_15.iloc[0][\"Importance\"]:.3f})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elliptic Feature Importance\n",
    "\n",
    "This chart shows the top 15 most important features for the XGBoost model. **Elliptic's transaction features (green) dominate**, with `feature_4` being by far the most important. Graph/behavioral features (red) like `is_chain_node` and `step_ratio` also appear, indicating they provide some complementary signal. This explains why Set A (transaction-only) performs so well, while Set C (combined) achieves a small additional improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 7: ROC Curve for Best Elliptic Model (Single Panel)\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot ROC curves for all folds\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "for fold in all_folds:\n",
    "    fpr, tpr, _ = roc_curve(fold['y_val'], fold['gb_proba'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    # Interpolate TPR at common FPR points\n",
    "    tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "    tpr_interp[0] = 0.0\n",
    "    tprs.append(tpr_interp)\n",
    "    \n",
    "    ax.plot(fpr, tpr, alpha=0.3, lw=1, label=f'Fold {fold[\"fold\"]} (AUC={roc_auc:.3f})')\n",
    "\n",
    "# Plot mean ROC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "ax.plot(mean_fpr, mean_tpr, color='blue', lw=3, \n",
    "        label=f'Mean ROC (AUC = {mean_auc:.3f} ± {std_auc:.3f})')\n",
    "\n",
    "# Plot random baseline\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.500)')\n",
    "\n",
    "# Shade std deviation\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='blue', alpha=0.2)\n",
    "\n",
    "ax.set_xlim([-0.02, 1.02])\n",
    "ax.set_ylim([-0.02, 1.02])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve: XGBoost on Combined Features (5-Fold CV)', fontsize=14)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('elliptic_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: elliptic_roc_curve.png')\n",
    "print(f'  Mean AUC: {mean_auc:.3f} ± {std_auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve Analysis\n",
    "\n",
    "This ROC curve shows the XGBoost model's discrimination ability across 5 cross-validation folds. **The mean AUC of ~0.99 indicates near-perfect ranking ability**—the model can almost perfectly separate illicit from licit transactions based on their predicted probabilities. All fold curves are far from the diagonal random baseline, demonstrating consistent strong performance across different data splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 8: Mendeley Feature Importance (High-Resolution Export)\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# RF importance (already computed as rf_importance)\n",
    "ax = axes[0]\n",
    "top_rf = rf_importance.head(10)\n",
    "ax.barh(top_rf['Feature'], top_rf['Importance'], color='forestgreen', alpha=0.8)\n",
    "ax.set_xlabel('Feature Importance', fontsize=11)\n",
    "ax.set_title('Random Forest: Top 10 Features', fontsize=12)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# LR coefficients (already computed as lr_coef)\n",
    "ax = axes[1]\n",
    "top_lr = lr_coef.head(10)\n",
    "colors = ['#e74c3c' if c < 0 else '#3498db' for c in top_lr['Coefficient']]\n",
    "ax.barh(top_lr['Feature'], top_lr['Coefficient'], color=colors, alpha=0.8)\n",
    "ax.set_xlabel('Coefficient (Blue=+, Red=-)', fontsize=11)\n",
    "ax.set_title('Logistic Regression: Top 10 Coefficients', fontsize=12)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle('Mendeley Scam Detection: Feature Importance Analysis', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mendeley_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: mendeley_feature_importance.png (high-resolution)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendeley Feature Importance\n",
    "\n",
    "This side-by-side comparison shows which behavioral features are most associated with scams in the Mendeley dataset. **Exchange rate, gas-adjusted value, and average value per output** rank highly for Random Forest. For Logistic Regression, **Transaction Value, Wallet Balance, and velocity per day** have the largest coefficients. Despite these associations, overall model performance remains weak (F1 ~0.50), indicating that these behavioral patterns have limited discriminatory power for scam detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 9: Mendeley Class Distribution\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "class_counts = y_mend.value_counts().sort_index()\n",
    "labels = ['Non-Scam', 'Scam']\n",
    "colors = ['steelblue', 'crimson']\n",
    "\n",
    "bars = ax.bar(labels, class_counts.values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Mendeley Dataset: Class Distribution', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, class_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "            f'{count}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add percentage annotations\n",
    "total = class_counts.sum()\n",
    "for bar, count in zip(bars, class_counts.values):\n",
    "    pct = count / total * 100\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2, \n",
    "            f'{pct:.1f}%', ha='center', va='center', fontsize=12, color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mendeley_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'✓ Saved: mendeley_class_distribution.png')\n",
    "print(f'  Non-Scam: {class_counts.iloc[0]} ({class_counts.iloc[0]/total*100:.1f}%)')\n",
    "print(f'  Scam: {class_counts.iloc[1]} ({class_counts.iloc[1]/total*100:.1f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendeley Class Distribution\n",
    "\n",
    "This bar chart shows the class distribution in the Mendeley scam dataset. The dataset is **nearly perfectly balanced** with ~50% scam and ~50% non-scam records. Despite this balance, model performance is only marginally above random chance (F1 ~0.50, AUC ~0.53), suggesting that the behavioral features in this dataset have weak discriminative power for scam detection, possibly due to noisy labels or insufficient feature granularity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
